# 超参数优化策略改进方案

## 一、当前超参数优化失败的原因分析

1. **优化目标不一致**
   - 当前使用单个子模型的F1分数作为优化目标
   - 最终评估指标是加权F1分数，两者目标不一致
   - 两个子模型单独优化后，整体性能可能下降

2. **搜索空间不合理**
   - 参数范围过大，导致搜索效率低下
   - 未基于之前的最佳参数调整搜索范围
   - 没有考虑参数之间的相关性

3. **迭代次数过多**
   - 100次迭代可能导致过拟合
   - 搜索空间过大时，随机搜索效率低下
   - 计算资源消耗过多

4. **模型复杂度问题**
   - 超参数优化可能导致模型过于复杂
   - 训练数据量有限时，复杂模型泛化能力下降

## 二、超参数优化策略改进方案

### 1. 调整优化目标

**核心改进**：使用最终的加权F1分数作为优化目标，而不是单个子模型的F1分数。

**实现方式**：
- 修改超参数优化逻辑，将两个子模型训练完成后，计算最终的加权F1分数
- 使用最终的加权F1分数作为优化目标
- 这样可以确保优化的是整体模型性能，而不是单个子模型性能

### 2. 调整搜索空间

**核心改进**：基于之前的最佳参数，缩小搜索范围，使其更集中在最优区域附近。

**具体调整**：

#### 平局模型 (draw_model) 参数空间
| 参数 | 当前范围 | 调整后范围 | 说明 |
|------|----------|------------|------|
| n_estimators | [200, 300, 500, 800, 1000] | [300, 500, 700, 900] | 基于之前的500调整，缩小范围 |
| learning_rate | [0.01, 0.05, 0.1, 0.15] | [0.05, 0.1, 0.12] | 基于之前的0.1调整，更集中在最优值附近 |
| max_depth | [3, 5, 7, 9] | [4, 5, 6] | 基于之前的5调整，缩小范围 |
| subsample | [0.6, 0.8, 1.0] | [0.7, 0.8, 0.9] | 基于之前的0.8调整，更集中 |
| colsample_bytree | [0.6, 0.8, 1.0] | [0.7, 0.8, 0.9] | 基于之前的0.8调整 |

#### 胜负模型 (win_loss_model) 参数空间
| 参数 | 当前范围 | 调整后范围 | 说明 |
|------|----------|------------|------|
| n_estimators | [500, 800, 1000, 1200, 1500] | [800, 1000, 1200] | 基于之前的1000调整 |
| learning_rate | [0.01, 0.02, 0.04, 0.06, 0.08] | [0.03, 0.04, 0.05] | 基于之前的0.04调整 |
| max_depth | [5, 6, 7, 8, 9] | [5, 6, 7] | 基于之前的6调整 |
| min_split_gain | [0, 0.01, 0.02, 0.04] | [0.01, 0.02, 0.03] | 基于之前的0.02调整 |
| min_child_samples | [20, 25, 30, 35, 40] | [22, 25, 28] | 基于之前的25调整 |

### 3. 减少迭代次数

**核心改进**：从100次迭代减少到30-50次，提高搜索效率。

**建议设置**：
- 平局模型：30次迭代
- 胜负模型：40次迭代

**理由**：
- 缩小搜索空间后，不需要太多迭代即可找到最优参数
- 减少计算资源消耗
- 降低过拟合风险

### 4. 优化策略调整

**4.1 分层优化策略**
- 第一层：优化最重要的参数（n_estimators, learning_rate, max_depth）
- 第二层：优化次要参数（subsample, colsample_bytree, reg_alpha, reg_lambda）
- 第三层：优化微调参数（min_split_gain, min_child_samples）

**4.2 使用贝叶斯优化**
- 替代随机搜索，使用贝叶斯优化（如Optuna库）
- 贝叶斯优化能利用之前的搜索结果，更高效地找到最优参数
- 收敛速度更快，需要的迭代次数更少

**4.3 合理的交叉验证策略**
- 使用5折交叉验证，提高评估的可靠性
- 确保训练集和测试集的分布一致
- 考虑时间序列特性，避免数据泄露

## 三、代码修改方案

### 1. 修改超参数优化目标

```python
def _tune_hyperparameters(self, X_train, y_train, X_test, y_test):
    """基于最终加权F1分数的超参数优化"""
    # 使用贝叶斯优化或其他优化方法
    # 训练两个子模型，计算最终加权F1分数
    # 返回最优参数
    pass
```

### 2. 修改搜索空间

```python
def _tune_binary_hyperparameters(self, X_train, y_train, model_name):
    # 调整后的参数搜索空间
    if is_draw_model:
        param_dist = {
            'n_estimators': [300, 500, 700, 900],
            'learning_rate': [0.05, 0.1, 0.12],
            'max_depth': [4, 5, 6],
            'num_leaves': [15, 31, 47],
            'subsample': [0.7, 0.8, 0.9],
            'colsample_bytree': [0.7, 0.8, 0.9],
            'reg_alpha': [0.05, 0.1, 0.2],
            'reg_lambda': [0.05, 0.1, 0.2],
            'min_split_gain': [0.01, 0.02, 0.03],
            'min_child_samples': [20, 25, 30]
        }
    elif is_win_loss_model:
        param_dist = {
            'n_estimators': [800, 1000, 1200],
            'learning_rate': [0.03, 0.04, 0.05],
            'max_depth': [5, 6, 7],
            'num_leaves': [31, 47, 63],
            'subsample': [0.75, 0.8, 0.85],
            'colsample_bytree': [0.75, 0.8, 0.85],
            'reg_alpha': [0.1, 0.15, 0.2],
            'reg_lambda': [0.1, 0.15, 0.2],
            'min_split_gain': [0.01, 0.02, 0.03],
            'min_child_samples': [22, 25, 28]
        }
    
    # 减少迭代次数
    random_search = RandomizedSearchCV(
        estimator=base_model,
        param_distributions=param_dist,
        n_iter=30,  # 减少迭代次数
        scoring='f1',
        cv=3,
        verbose=2,
        random_state=42,
        n_jobs=1
    )
```

### 3. 引入贝叶斯优化

```python
# 安装optuna：pip install optuna
import optuna

def objective(trial):
    # 定义参数搜索空间
    n_estimators = trial.suggest_int('n_estimators', 500, 1500, step=100)
    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.1, step=0.01)
    max_depth = trial.suggest_int('max_depth', 3, 8, step=1)
    
    # 训练模型，计算加权F1分数
    # 返回加权F1分数
    return weighted_f1

# 创建研究对象
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=40)  # 减少迭代次数
```

## 四、实施步骤

1. **修改代码**：按照上述方案修改`hierarchical_trainer.py`中的超参数优化逻辑
2. **调整搜索空间**：更新`_tune_binary_hyperparameters`方法中的参数搜索空间
3. **减少迭代次数**：将`n_iter`从100改为30-50
4. **测试优化效果**：运行训练脚本，验证超参数优化后的模型性能
5. **逐步调整**：根据测试结果，进一步调整搜索空间和迭代次数

## 五、预期效果

1. **提高优化效率**：减少迭代次数，缩短训练时间
2. **提升模型性能**：使用最终加权F1分数作为优化目标，确保整体性能提升
3. **降低过拟合风险**：缩小搜索空间，减少过拟合可能性
4. **更稳定的结果**：基于之前的最佳参数调整搜索范围，结果更稳定

## 六、注意事项

1. **数据泄露**：确保超参数优化过程中没有数据泄露
2. **时间成本**：贝叶斯优化虽然效率更高，但实现复杂度增加
3. **可复现性**：设置随机种子，确保结果可复现
4. **模型保存**：保存优化后的最佳参数，方便后续使用
5. **性能监控**：实时监控训练过程，及时调整策略

通过上述改进方案，可以有效解决当前超参数优化失败的问题，提高模型性能和训练效率。